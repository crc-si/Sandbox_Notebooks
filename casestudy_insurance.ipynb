{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datacube\n",
    "from datacube.storage import masking\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# Load utility functions\n",
    "from utils.DEADataHandling import load_clearsentinel2, load_clearlandsat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import yield data\n",
    "\n",
    "Need more localised/specific data. Currently using harvest values for all of NSW for all winter crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_nsw = pd.read_csv(\"ancillary_data/NSW_Yield_Data.csv\", parse_dates=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yield_nsw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Landsat geomedian for Harden, NSW\n",
    "\n",
    "Need higher-cadence data. Currently using geomedian for whole year over Harden, which is primarily farmland, but not entirely. Need to find a way to exclude non-farm regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harden_lat = (-34.7, -34.6)\n",
    "harden_lon = (148.3, 148.4)\n",
    "time_range = (1989, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the datacube\n",
    "dc = datacube.Datacube(app='index-insurance')\n",
    "\n",
    "# Create the 'query' dictionary object, which contains the longitudes, latitudes and time provided above\n",
    "query = {\n",
    "    'y': harden_lat,\n",
    "    'x': harden_lon,\n",
    "    'time': time_range,\n",
    "    'output_crs': 'EPSG:28352',\n",
    "    'resolution': (-25, 25)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Landsat 8 data for the time and area in the query. This may take several minutes, so please be patient.\n",
    "landsat8_ds = dc.load(\n",
    "    product='ls8_nbart_geomedian_annual',\n",
    "    **query,\n",
    "    measurements=['red', 'green', 'blue', 'nir']\n",
    ")\n",
    "\n",
    "# Load Landsat 7 data for the time and area in the query. This may take several minutes, so please be patient.\n",
    "landsat7_ds = dc.load(\n",
    "    product='ls7_nbart_geomedian_annual',\n",
    "    **query,\n",
    "    measurements=['red', 'green', 'blue', 'nir']\n",
    ")\n",
    "\n",
    "# Load Landsat 5 data for the time and area in the query. This may take several minutes, so please be patient.\n",
    "landsat5_ds = dc.load(\n",
    "    product='ls5_nbart_geomedian_annual',\n",
    "    **query,\n",
    "    measurements=['red', 'green', 'blue', 'nir']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and combine Landsat datasets\n",
    "Try and remove Landsat images affected by SLC error (Landsat 7). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat5_filtered_1 = landsat5_ds.sel(time=landsat5_ds.time < np.datetime64('2001-01-01'))\n",
    "landsat5_filtered_2 = landsat5_ds.sel(time=landsat5_ds.time > np.datetime64('2003-01-01'))\n",
    "landsat7_filtered = landsat7_ds.sel(time=landsat7_ds.time < np.datetime64('2004-01-01'))\n",
    "\n",
    "landsat_combined = xr.concat([landsat5_filtered_1, landsat7_filtered, landsat5_filtered_2, landsat8_ds], dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDVI for combined Landsat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_combined['ndvi'] = (landsat_combined.nir - landsat_combined.red)/(landsat_combined.nir + landsat_combined.red)\n",
    "landsat_mean = landsat_combined.mean(dim=['x','y'])\n",
    "\n",
    "ndvi_df = landsat_mean.ndvi.to_dataframe()\n",
    "\n",
    "ndvi_yield = pd.merge(yield_nsw, ndvi_df, on='time')\n",
    "print(landsat_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Yield vs. NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_yield.plot.scatter(x='ndvi', y='Yield_t_per_hectare')\n",
    "plt.xlabel('NDVI')\n",
    "plt.ylabel('Yield (t/ha)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit linear regression to Yield vs. NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X = np.asarray(ndvi_yield['ndvi']).reshape(-1, 1)\n",
    "y = ndvi_yield['Yield_t_per_hectare']\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "\n",
    "predictions = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_yield.plot.scatter(x='ndvi', y='Yield_t_per_hectare')\n",
    "plt.plot(X, predictions)\n",
    "plt.xlabel('NDVI')\n",
    "plt.ylabel('Yield (t/ha)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_yield['ndvi'].hist(bins=10)\n",
    "plt.xlabel('NDVI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_yield['Yield_t_per_hectare'].hist(bins=10)\n",
    "plt.xlabel('Yield (t/ha)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sentinel 2 for Harden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the product measurments to load from Sentinel-2\n",
    "measurements = (\n",
    "    'nbar_red',\n",
    "    'nbar_green',\n",
    "    'nbar_blue',\n",
    "    'nbar_nir_1',\n",
    ")\n",
    "\n",
    "# Specify the minimum proportion of good quality pixels for an image.\n",
    "# The image will be excluded if masking results in fewer pixels than\n",
    "# the set proportion.\n",
    "# Setting this to 0.0 includes all images\n",
    "min_good_pixel_prop = 0.5\n",
    "\n",
    "# Load the data and mask out bad quality pixels\n",
    "ds_s2 = load_clearsentinel2(\n",
    "    dc=dc,\n",
    "    query=query,\n",
    "    sensors=['s2a', 's2b'],\n",
    "    product='ard',\n",
    "    bands_of_interest=measurements,\n",
    "    masked_prop=min_good_pixel_prop\n",
    ")\n",
    "\n",
    "\n",
    "# sentinel_2a_ds = dc.load(\n",
    "#     product='s2a_ard_granule',\n",
    "#     **query,\n",
    "#     measurements=['nbar_red', 'nbar_green', 'nbar_blue', 'nbar_nir_1'],\n",
    "#     group_by='solar_day'\n",
    "# )\n",
    "# print(sentinel_2a_ds)\n",
    "\n",
    "# sentinel_2b_ds = dc.load(\n",
    "#     product='s2b_ard_granule',\n",
    "#     **query,\n",
    "#     measurements=['nbar_red', 'nbar_green', 'nbar_blue', 'nbar_nir_1'],\n",
    "#     group_by='solar_day'\n",
    "# )\n",
    "# print(sentinel_2b_ds)\n",
    "\n",
    "# sentinel_2_ds = xr.concat([sentinel_2a_ds, sentinel_2b_ds], dim='time')\n",
    "# print(sentinel_2_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import three_band_image\n",
    "\n",
    "time = 10\n",
    "time_string = str(ds_s2.time.isel(time=time).values).split('.')[0]\n",
    "\n",
    "test = three_band_image(ds_s2, ['nbar_red', 'nbar_green', 'nbar_blue'], time=time, figsize=[20,20])\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Timestep {}\".format(time_string), fontweight='bold', fontsize=16)\n",
    "ax.set_xticklabels(ds_s2.x.values)\n",
    "ax.set_yticklabels(ds_s2.y.values)\n",
    "ax.set_xlabel('Easting', fontweight='bold')\n",
    "ax.set_ylabel('Northing', fontweight='bold')\n",
    "\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2['ndvi'] = (ds_s2.nbar_nir_1 - ds_s2.nbar_red)/(ds_s2.nbar_nir_1 + ds_s2.nbar_red)\n",
    "ds_s2_mean = ds_s2.mean(dim=['x','y'])\n",
    "\n",
    "s2_ndvi_df = ds_s2.ndvi.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s2_mean.ndvi.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LS8 Fractional Cover for Harden\n",
    "\n",
    "Load photosynthetic vegetation measurement from Landsat 5,8 (FC currently unavailable in sandbox for Landsat 7). Also load WoFS feature layers to make mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls8_fc_ds = dc.load(\n",
    "    product='ls8_fc_albers',\n",
    "    **query,\n",
    "    measurements=['PV']\n",
    ")\n",
    "\n",
    "ls5_fc_ds = dc.load(\n",
    "    product='ls5_fc_albers',\n",
    "    **query,\n",
    "    measurements=['PV']\n",
    ")\n",
    "\n",
    "ls_fc_combined_ds = xr.concat([ls5_fc_ds, ls8_fc_ds], dim='time')\n",
    "\n",
    "wofls_ds = dc.load(product='wofs_albers', **query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make mask based on which pixels are classified as dry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wofl_mask = masking.make_mask(wofls_ds, dry=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply mask to combined Landsat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_fc_combined_masked_mean = ls_fc_combined_masked_ds.mean(dim=['x','y'])\n",
    "\n",
    "ls_fc_combined_masked_mean.PV.plot.line('b-', aspect=5, size=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_fc_resampled = ls_fc_combined_masked_mean.resample(time='1W').interpolate('linear')\n",
    "\n",
    "ls_fc_weekgroup_average = ls_fc_resampled.PV.groupby('time.week').mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ls_fc_resampled_test.plot.line()\n",
    "ax.axvspan(xmin=38, xmax=52, alpha=0.25, color='green', label=\"Harvest\")\n",
    "ax.axvspan(xmin=16, xmax=23, alpha=0.25, color='red', label=\"Sowing\")\n",
    "plt.legend()\n",
    "plt.title(\"Weekly average PV over archive\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = ls_fc_resampled[ls_fc_resampled.groupby('time.month').mean()\n",
    "print(monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "november_ds = ls_fc_resampled.where(ls_fc_resampled.time.dt.month == 11).dropna('time').groupby('time.year').mean()\n",
    "\n",
    "yield_nsw['year'] = yield_nsw['time'].dt.year\n",
    "test = yield_nsw.set_index(['year']).to_xarray()\n",
    "\n",
    "november_pv_yield = xr.merge([november_ds, test], join='inner').to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = november_pv_yield.plot.scatter(x='PV', y='Yield_t_per_hectare', figsize=(10,10))\n",
    "for index, row in november_pv_yield.iterrows():\n",
    "     ax.annotate(index, (row['PV'], row['Yield_t_per_hectare']))\n",
    "\n",
    "ax.set_xlabel('PV')\n",
    "ax.set_ylabel('Yield (t/ha)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pv = np.asarray(november_pv_yield['PV']).reshape(-1, 1)\n",
    "y_yield = november_pv_yield['Yield_t_per_hectare']\n",
    "\n",
    "lm_yield = linear_model.LinearRegression()\n",
    "model_yield = lm_yield.fit(X_pv,y_yield)\n",
    "\n",
    "predictions_yield = lm_yield.predict(X_pv)\n",
    "\n",
    "print(lm_yield.score(X_pv,y_yield))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "november_pv_yield.plot.scatter(x='PV', y='Yield_t_per_hectare')\n",
    "plt.plot(X_pv, predictions_yield)\n",
    "plt.xlabel('NDVI')\n",
    "plt.ylabel('Yield (t/ha)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
